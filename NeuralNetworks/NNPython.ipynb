{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20110bbd-1d60-45fb-9168-6692885a088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 50)\n",
      "(50, 25)\n",
      "(25, 2)\n",
      "iteration 0: loss 0.693145\n",
      "iteration 50: loss 0.693094\n",
      "iteration 100: loss 0.692300\n",
      "iteration 150: loss 0.418811\n",
      "iteration 200: loss 0.451199\n",
      "iteration 250: loss 0.240887\n",
      "iteration 300: loss 0.172424\n",
      "iteration 350: loss 0.175255\n",
      "iteration 400: loss 0.140763\n",
      "iteration 450: loss 0.111915\n",
      "[[9.06350390e-01 9.36496102e-02]\n",
      " [8.97374312e-01 1.02625688e-01]\n",
      " [8.96612985e-01 1.03387015e-01]\n",
      " [8.84483024e-01 1.15516976e-01]\n",
      " [8.91197096e-01 1.08802904e-01]\n",
      " [8.82319869e-01 1.17680131e-01]\n",
      " [8.91174358e-01 1.08825642e-01]\n",
      " [8.88335497e-01 1.11664503e-01]\n",
      " [9.16949194e-01 8.30508056e-02]\n",
      " [9.24229648e-01 7.57703522e-02]\n",
      " [9.11246895e-01 8.87531055e-02]\n",
      " [9.08267459e-01 9.17325412e-02]\n",
      " [9.60454577e-01 3.95454234e-02]\n",
      " [9.66803585e-01 3.31964145e-02]\n",
      " [9.49524466e-01 5.04755342e-02]\n",
      " [9.80901991e-01 1.90980090e-02]\n",
      " [9.72373911e-01 2.76260895e-02]\n",
      " [9.77116370e-01 2.28836301e-02]\n",
      " [9.88699140e-01 1.13008602e-02]\n",
      " [9.88849360e-01 1.11506403e-02]\n",
      " [9.90102378e-01 9.89762250e-03]\n",
      " [9.90457244e-01 9.54275573e-03]\n",
      " [9.90807454e-01 9.19254641e-03]\n",
      " [9.90780129e-01 9.21987107e-03]\n",
      " [9.91507882e-01 8.49211808e-03]\n",
      " [9.91272891e-01 8.72710949e-03]\n",
      " [9.91581138e-01 8.41886156e-03]\n",
      " [9.91441042e-01 8.55895801e-03]\n",
      " [9.92312519e-01 7.68748075e-03]\n",
      " [9.92473361e-01 7.52663856e-03]\n",
      " [9.92895203e-01 7.10479710e-03]\n",
      " [9.92391892e-01 7.60810839e-03]\n",
      " [9.91847319e-01 8.15268120e-03]\n",
      " [9.92470767e-01 7.52923258e-03]\n",
      " [9.93293544e-01 6.70645556e-03]\n",
      " [9.93023469e-01 6.97653130e-03]\n",
      " [9.90816136e-01 9.18386393e-03]\n",
      " [9.90735476e-01 9.26452406e-03]\n",
      " [9.92406006e-01 7.59399363e-03]\n",
      " [9.88889375e-01 1.11106255e-02]\n",
      " [9.92855061e-01 7.14493865e-03]\n",
      " [9.92091888e-01 7.90811241e-03]\n",
      " [9.91395326e-01 8.60467415e-03]\n",
      " [9.88478909e-01 1.15210906e-02]\n",
      " [9.93932291e-01 6.06770916e-03]\n",
      " [9.95365624e-01 4.63437644e-03]\n",
      " [9.90564080e-01 9.43592032e-03]\n",
      " [9.94377641e-01 5.62235893e-03]\n",
      " [9.95572362e-01 4.42763760e-03]\n",
      " [9.95939916e-01 4.06008393e-03]\n",
      " [9.95735055e-01 4.26494505e-03]\n",
      " [9.98081015e-01 1.91898536e-03]\n",
      " [9.95742558e-01 4.25744160e-03]\n",
      " [9.98299272e-01 1.70072806e-03]\n",
      " [9.97182172e-01 2.81782813e-03]\n",
      " [9.98463019e-01 1.53698098e-03]\n",
      " [9.98647282e-01 1.35271795e-03]\n",
      " [9.98962829e-01 1.03717101e-03]\n",
      " [9.98747980e-01 1.25202042e-03]\n",
      " [9.98769336e-01 1.23066365e-03]\n",
      " [9.98974558e-01 1.02544241e-03]\n",
      " [9.99123195e-01 8.76804749e-04]\n",
      " [9.99561123e-01 4.38876990e-04]\n",
      " [9.99863148e-01 1.36851972e-04]\n",
      " [9.99795687e-01 2.04312754e-04]\n",
      " [9.99965182e-01 3.48181264e-05]\n",
      " [9.99972892e-01 2.71084943e-05]\n",
      " [9.99938597e-01 6.14030608e-05]\n",
      " [9.99976260e-01 2.37398040e-05]\n",
      " [9.99986989e-01 1.30110575e-05]\n",
      " [9.99989715e-01 1.02850570e-05]\n",
      " [9.99995725e-01 4.27476551e-06]\n",
      " [9.99996291e-01 3.70940607e-06]\n",
      " [9.99994547e-01 5.45345637e-06]\n",
      " [9.99997964e-01 2.03639863e-06]\n",
      " [9.99997879e-01 2.12141093e-06]\n",
      " [9.99998051e-01 1.94894385e-06]\n",
      " [9.99999227e-01 7.72770122e-07]\n",
      " [9.99999330e-01 6.70177543e-07]\n",
      " [9.99999411e-01 5.88587799e-07]\n",
      " [9.99999058e-01 9.42317959e-07]\n",
      " [9.99999524e-01 4.75807877e-07]\n",
      " [9.99999391e-01 6.09289123e-07]\n",
      " [9.99998486e-01 1.51409678e-06]\n",
      " [9.99999106e-01 8.94189832e-07]\n",
      " [9.99998857e-01 1.14289095e-06]\n",
      " [9.99992055e-01 7.94509252e-06]\n",
      " [9.99964634e-01 3.53655867e-05]\n",
      " [9.99983560e-01 1.64403163e-05]\n",
      " [9.99941618e-01 5.83818345e-05]\n",
      " [9.99710420e-01 2.89579849e-04]\n",
      " [9.99966275e-01 3.37252511e-05]\n",
      " [9.99892999e-01 1.07000704e-04]\n",
      " [9.99610534e-01 3.89465582e-04]\n",
      " [9.99528512e-01 4.71487577e-04]\n",
      " [9.93599007e-01 6.40099266e-03]\n",
      " [9.93017023e-01 6.98297745e-03]\n",
      " [9.93086989e-01 6.91301146e-03]\n",
      " [9.58429319e-01 4.15706806e-02]\n",
      " [8.45463129e-01 1.54536871e-01]\n",
      " [9.06350390e-01 9.36496102e-02]\n",
      " [8.91267010e-01 1.08732990e-01]\n",
      " [8.75138029e-01 1.24861971e-01]\n",
      " [8.52030720e-01 1.47969280e-01]\n",
      " [8.11589966e-01 1.88410034e-01]\n",
      " [7.66224575e-01 2.33775425e-01]\n",
      " [7.27581472e-01 2.72418528e-01]\n",
      " [6.84970195e-01 3.15029805e-01]\n",
      " [6.31421941e-01 3.68578059e-01]\n",
      " [5.29938751e-01 4.70061249e-01]\n",
      " [4.77217482e-01 5.22782518e-01]\n",
      " [4.41206063e-01 5.58793937e-01]\n",
      " [3.93058581e-01 6.06941419e-01]\n",
      " [3.49771324e-01 6.50228676e-01]\n",
      " [2.56344736e-01 7.43655264e-01]\n",
      " [1.78179679e-01 8.21820321e-01]\n",
      " [8.65532718e-02 9.13446728e-01]\n",
      " [1.13580005e-01 8.86419995e-01]\n",
      " [3.89159290e-02 9.61084071e-01]\n",
      " [5.57312062e-02 9.44268794e-01]\n",
      " [3.13560936e-02 9.68643906e-01]\n",
      " [2.39412332e-02 9.76058767e-01]\n",
      " [8.61399393e-03 9.91386006e-01]\n",
      " [5.03901246e-03 9.94960988e-01]\n",
      " [5.25923383e-03 9.94740766e-01]\n",
      " [3.47264314e-03 9.96527357e-01]\n",
      " [2.47513344e-03 9.97524867e-01]\n",
      " [1.34407732e-03 9.98655923e-01]\n",
      " [9.98633322e-04 9.99001367e-01]\n",
      " [5.13774009e-04 9.99486226e-01]\n",
      " [3.74577478e-04 9.99625423e-01]\n",
      " [2.99090506e-04 9.99700909e-01]\n",
      " [1.84500796e-04 9.99815499e-01]\n",
      " [1.39649116e-04 9.99860351e-01]\n",
      " [9.98772194e-05 9.99900123e-01]\n",
      " [6.84053942e-05 9.99931595e-01]\n",
      " [6.40022627e-05 9.99935998e-01]\n",
      " [3.72134679e-05 9.99962787e-01]\n",
      " [3.86922814e-05 9.99961308e-01]\n",
      " [5.50600785e-05 9.99944940e-01]\n",
      " [3.96241005e-05 9.99960376e-01]\n",
      " [6.05241282e-05 9.99939476e-01]\n",
      " [6.34679488e-05 9.99936532e-01]\n",
      " [3.69416014e-05 9.99963058e-01]\n",
      " [8.15513481e-05 9.99918449e-01]\n",
      " [5.32695145e-05 9.99946730e-01]\n",
      " [8.09660055e-05 9.99919034e-01]\n",
      " [1.81033437e-04 9.99818967e-01]\n",
      " [9.58047418e-05 9.99904195e-01]\n",
      " [7.69371157e-05 9.99923063e-01]\n",
      " [8.54642564e-05 9.99914536e-01]\n",
      " [3.77942952e-04 9.99622057e-01]\n",
      " [2.21034699e-04 9.99778965e-01]\n",
      " [1.26878896e-04 9.99873121e-01]\n",
      " [4.19559193e-04 9.99580441e-01]\n",
      " [2.33767812e-04 9.99766232e-01]\n",
      " [5.83526368e-04 9.99416474e-01]\n",
      " [2.88676846e-03 9.97113232e-01]\n",
      " [4.47957746e-03 9.95520423e-01]\n",
      " [4.88221895e-03 9.95117781e-01]\n",
      " [4.94503008e-02 9.50549699e-01]\n",
      " [5.57355515e-02 9.44264449e-01]\n",
      " [2.88969450e-02 9.71103055e-01]\n",
      " [5.12662382e-02 9.48733762e-01]\n",
      " [2.61786853e-02 9.73821315e-01]\n",
      " [3.27792585e-02 9.67220742e-01]\n",
      " [2.35852909e-02 9.76414709e-01]\n",
      " [1.35834047e-02 9.86416595e-01]\n",
      " [9.44016047e-03 9.90559840e-01]\n",
      " [2.16355078e-03 9.97836449e-01]\n",
      " [1.18558309e-03 9.98814417e-01]\n",
      " [1.05347104e-03 9.98946529e-01]\n",
      " [1.45009088e-04 9.99854991e-01]\n",
      " [9.59396458e-05 9.99904060e-01]\n",
      " [8.62781141e-05 9.99913722e-01]\n",
      " [3.38461895e-05 9.99966154e-01]\n",
      " [2.32737802e-05 9.99976726e-01]\n",
      " [1.83565327e-05 9.99981643e-01]\n",
      " [9.57374819e-06 9.99990426e-01]\n",
      " [6.07679708e-06 9.99993923e-01]\n",
      " [4.39782281e-06 9.99995602e-01]\n",
      " [5.77346919e-06 9.99994227e-01]\n",
      " [4.91455292e-06 9.99995085e-01]\n",
      " [2.81423290e-06 9.99997186e-01]\n",
      " [2.14358717e-06 9.99997856e-01]\n",
      " [7.52506074e-06 9.99992475e-01]\n",
      " [1.70054974e-06 9.99998299e-01]\n",
      " [1.30269008e-05 9.99986973e-01]\n",
      " [4.06651152e-06 9.99995933e-01]\n",
      " [5.15577462e-06 9.99994844e-01]\n",
      " [3.52327289e-06 9.99996477e-01]\n",
      " [1.82069059e-05 9.99981793e-01]\n",
      " [2.25197772e-05 9.99977480e-01]\n",
      " [9.54430561e-06 9.99990456e-01]\n",
      " [1.30524034e-05 9.99986948e-01]\n",
      " [2.95516296e-04 9.99704484e-01]\n",
      " [2.26453988e-05 9.99977355e-01]\n",
      " [1.85267589e-03 9.98147324e-01]\n",
      " [2.85354601e-04 9.99714645e-01]\n",
      " [2.08448688e-02 9.79155131e-01]]\n",
      "iteration 500: loss 0.095605\n",
      "iteration 550: loss 0.066206\n",
      "iteration 600: loss 0.055241\n",
      "iteration 650: loss 0.051571\n",
      "iteration 700: loss 0.039149\n",
      "iteration 750: loss 0.036705\n",
      "iteration 800: loss 0.036065\n",
      "iteration 850: loss 0.029040\n",
      "iteration 900: loss 0.029121\n",
      "iteration 950: loss 0.027052\n",
      "iteration 1000: loss 0.024923\n",
      "iteration 1050: loss 0.024326\n",
      "iteration 1100: loss 0.023651\n",
      "iteration 1150: loss 0.021559\n",
      "iteration 1200: loss 0.022272\n",
      "iteration 1250: loss 0.025477\n",
      "iteration 1300: loss 0.019710\n",
      "iteration 1350: loss 0.018580\n",
      "iteration 1400: loss 0.017712\n",
      "iteration 1450: loss 0.019880\n",
      "iteration 1500: loss 0.017029\n",
      "iteration 1550: loss 0.017866\n",
      "iteration 1600: loss 0.018254\n",
      "iteration 1650: loss 0.016089\n",
      "iteration 1700: loss 0.016143\n",
      "iteration 1750: loss 0.016386\n",
      "iteration 1800: loss 0.016589\n",
      "iteration 1850: loss 0.016378\n",
      "iteration 1900: loss 0.015571\n",
      "iteration 1950: loss 0.015516\n",
      "iteration 2000: loss 0.014986\n",
      "iteration 2050: loss 0.016165\n",
      "iteration 2100: loss 0.016021\n",
      "iteration 2150: loss 0.014922\n",
      "iteration 2200: loss 0.014565\n",
      "iteration 2250: loss 0.015556\n",
      "iteration 2300: loss 0.014013\n",
      "iteration 2350: loss 0.014868\n",
      "iteration 2400: loss 0.013720\n",
      "iteration 2450: loss 0.013876\n",
      "iteration 2500: loss 0.013849\n",
      "iteration 2550: loss 0.013878\n",
      "iteration 2600: loss 0.012904\n",
      "iteration 2650: loss 0.014141\n",
      "iteration 2700: loss 0.013060\n",
      "iteration 2750: loss 0.014925\n",
      "iteration 2800: loss 0.013322\n",
      "iteration 2850: loss 0.012790\n",
      "iteration 2900: loss 0.013991\n",
      "iteration 2950: loss 0.014514\n",
      "iteration 3000: loss 0.012698\n",
      "iteration 3050: loss 0.012876\n",
      "iteration 3100: loss 0.013675\n",
      "iteration 3150: loss 0.012316\n",
      "iteration 3200: loss 0.012535\n",
      "iteration 3250: loss 0.013300\n",
      "iteration 3300: loss 0.012074\n",
      "iteration 3350: loss 0.012315\n",
      "iteration 3400: loss 0.011825\n",
      "iteration 3450: loss 0.013249\n",
      "iteration 3500: loss 0.013268\n",
      "iteration 3550: loss 0.012948\n",
      "iteration 3600: loss 0.011947\n",
      "iteration 3650: loss 0.012244\n",
      "iteration 3700: loss 0.012693\n",
      "iteration 3750: loss 0.011806\n",
      "iteration 3800: loss 0.011818\n",
      "iteration 3850: loss 0.011653\n",
      "iteration 3900: loss 0.011665\n",
      "iteration 3950: loss 0.011771\n",
      "iteration 4000: loss 0.011896\n",
      "iteration 4050: loss 0.013047\n",
      "iteration 4100: loss 0.011870\n",
      "iteration 4150: loss 0.011333\n",
      "iteration 4200: loss 0.011673\n",
      "iteration 4250: loss 0.011462\n",
      "iteration 4300: loss 0.011468\n",
      "iteration 4350: loss 0.011495\n",
      "iteration 4400: loss 0.012820\n",
      "iteration 4450: loss 0.010560\n",
      "iteration 4500: loss 0.011535\n",
      "iteration 4550: loss 0.012096\n",
      "iteration 4600: loss 0.012032\n",
      "iteration 4650: loss 0.011600\n",
      "iteration 4700: loss 0.011834\n",
      "iteration 4750: loss 0.011647\n",
      "iteration 4800: loss 0.010847\n",
      "iteration 4850: loss 0.011490\n",
      "iteration 4900: loss 0.011152\n",
      "iteration 4950: loss 0.010770\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = 100 # number of points per class\n",
    "D = 2 # dimensionality\n",
    "K = 2 # number of classes\n",
    "X = np.zeros((N*K,D)) # data matrix (each row = single example)\n",
    "y = np.zeros(N*K, dtype='uint8') # class labels\n",
    "\n",
    "for j in range(K):\n",
    "  ix = range(N*j,N*(j+1))\n",
    "  r = np.linspace(0.0,1,N) # radius\n",
    "  t = np.linspace(j*4,(j+1)*4,N) + np.random.rand(N)*0.2 # theta\n",
    "  X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "  y[ix] = j\n",
    "\n",
    "# Initialize parameters randomly\n",
    "h1 = 50  # Size of the first hidden layer\n",
    "h2 = 25  # Size of the second hidden layer\n",
    "W1 = 0.01 * np.random.randn(D, h1)\n",
    "b1 = np.zeros((1, h1))\n",
    "W2 = 0.01 * np.random.randn(h1, h2)\n",
    "b2 = np.zeros((1, h2))\n",
    "W3 = 0.01 * np.random.randn(h2, K)\n",
    "b3 = np.zeros((1, K))\n",
    "\n",
    "print(W1.shape)\n",
    "print(W2.shape)\n",
    "print(W3.shape)\n",
    "\n",
    "# Some hyperparameters\n",
    "step_size = 1\n",
    "\n",
    "# Gradient descent loop\n",
    "num_examples = X.shape[0]\n",
    "for i in range(5000):\n",
    "    # Forward pass\n",
    "    hidden_layer1 = np.maximum(0, np.dot(X, W1) + b1)  # ReLU activation for the first hidden layer\n",
    "    hidden_layer2 = np.maximum(0, np.dot(hidden_layer1, W2) + b2)  # ReLU activation for the second hidden layer\n",
    "    scores = np.dot(hidden_layer2, W3) + b3\n",
    "\n",
    "    # Compute the class probabilities\n",
    "    exp_scores = np.exp(scores)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)  # [N x K]\n",
    "\n",
    "    if i == 499:\n",
    "        print(probs)\n",
    "\n",
    "    # Compute the loss: average cross-entropy loss and regularization\n",
    "    correct_logprobs = -np.log(probs[range(num_examples), y])\n",
    "    data_loss = np.sum(correct_logprobs) / num_examples\n",
    "\n",
    "    # Add regularization to the loss\n",
    "    # reg = 0.01  # Regularization strength (you can adjust this)\n",
    "    # reg_loss = 0.5 * reg * (np.sum(W1 * W1) + np.sum(W2 * W2) + np.sum(W3 * W3))\n",
    "    #loss = data_loss + reg_loss\n",
    "    loss = data_loss\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print(\"iteration %d: loss %f\" % (i, loss))\n",
    "\n",
    "    # Backpropagation\n",
    "    dscores = probs\n",
    "    dscores[range(num_examples), y] -= 1\n",
    "    dscores /= num_examples\n",
    "\n",
    "    # Backpropagation for the third layer\n",
    "    dW3 = np.dot(hidden_layer2.T, dscores)\n",
    "    db3 = np.sum(dscores, axis=0, keepdims=True)\n",
    "    dhidden2 = np.dot(dscores, W3.T)\n",
    "    dhidden2[hidden_layer2 <= 0] = 0\n",
    "\n",
    "    # Backpropagation for the second hidden layer\n",
    "    dhidden2[hidden_layer2 <= 0] = 0\n",
    "    dW2 = np.dot(hidden_layer1.T, dhidden2)\n",
    "    db2 = np.sum(dhidden2, axis=0, keepdims=True)\n",
    "    dhidden1 = np.dot(dhidden2, W2.T)\n",
    "    dhidden1[hidden_layer1 <= 0] = 0\n",
    "\n",
    "    # Backpropagation for the first hidden layer\n",
    "    dW1 = np.dot(X.T, dhidden1)\n",
    "    db1 = np.sum(dhidden1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update parameters\n",
    "    W1 += -step_size * dW1\n",
    "    b1 += -step_size * db1\n",
    "    W2 += -step_size * dW2\n",
    "    b2 += -step_size * db2\n",
    "    W3 += -step_size * dW3\n",
    "    b3 += -step_size * db3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be9c32-784b-4d44-a23d-87531102a307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f828e9-8427-4b05-be3a-fee64b871930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "432ceacb5660315e79a1c9b397e9944ac6b0feb83637c3f964102aa0e39af5b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
